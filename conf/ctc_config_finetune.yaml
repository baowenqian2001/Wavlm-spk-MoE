#exp name and save dir
exp_name: 'finetune/'
checkpoint_dir: 'checkpoint/'

path_base: wavlm-base
path_base_plus: 'wavlm-base-plus'
path_large: 'wavlm-large'
path_wav2vec_base: 'wav2vec2-base-960h'
path_wav2vec: 'wav2vec2-large-960h'
path_wav2vec_large_lv60_self: 'wav2vec2-large-960h-lv60-self'
path_wav2vec_large_lv60: 'wav2vec2-large-lv60'
path_wav2vec2_large_xlsr: 'wav2vec2-large-xlsr-53'

model_path: "/root/workspace/MDD/CTC-Attention-Mispronunciation/egs/wavlm/model/wavlm-base"
model: wavlm-base-moe-spk
evaluation_strategy: 'steps'
#Data
vocab_file: 'data/units'
train_scp_path: 'data/train/fbank.scp'
train_lab_path: 'data/train/phn_text'
train_trans_path: 'data/train/transcript_phn_text'
valid_scp_path: 'data/dev/fbank.scp'
valid_lab_path: 'data/dev/phn_text'
valid_trans_path: 'data/dev/transcript_phn_text'
train_wav_path: 'data/train/wav.scp'
valid_wav_path: 'data/dev/wav.scp'
left_ctx: 0
right_ctx: 2
n_skip_frame: 2
n_downsample: 2
num_workers: 1
shuffle_train: True
feature_dim: 81
output_class_dim: 39
mel: False
feature_type: waveform #"fbank"

#Model
rnn_input_size: 243
rnn_hidden_size: 384
rnn_layers: 4
rnn_type: "nn.LSTM"
bidirectional: True
batch_norm: True
drop_out: 0.2

#CNN
add_cnn: True
layers: 2
channel: "[(1, 32), (32, 32)]"
kernel_size: "[(3, 3), (3, 3)]"
stride: "[(1, 2), (2, 2)]"
padding: "[(1, 1), (1, 1)]"
pooling: "None"
batch_norm: True
activation_function: "relu"

#[Training]
use_gpu: True
init_lr: 0.0001
lrf: 0.0001
num_epoches: 50
end_adjust_acc: 2
lr_decay: 0.5
batch_size: 12
weight_decay: 0.0005
seed: 1234
verbose_step: 100
tensorboard: True
dist_url: 'env://'

#[test]
test_scp_path: 'data/test/fbank.scp'
test_lab_path: 'data/test/phn_text'
test_trans_path: 'data/test/transcript_phn_text'
test_wav_path: 'data/test/wav.scp'
decode_type: "Beam"
beam_width: 10
lm_alpha: 0
lm_path: 'data/lm_phone_bg.arpa'

